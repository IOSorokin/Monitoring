# Домашнее задание к занятию "13.Системы мониторинга"
## Обязательные задания

### 1. Вас пригласили настроить мониторинг на проект. На онбординге вам рассказали, что проект представляет из себя платформу для вычислений с выдачей текстовых отчетов, которые сохраняются на диск. Взаимодействие с платформой осуществляется по протоколу http. Также вам отметили, что вычисления загружают ЦПУ. Какой минимальный набор метрик вы выведите в мониторинг и почему?
```
Очередь обращений на диск
IO/s — количество операций ввода вывода в секунду.
MB/s — количество переданных мегабайт в секунду.
Оставшееся место на диске
Использование процессора и его нагрузка
Количество активных подключений
Ошибки подключений
Ошибки сервера
```

### 2. Менеджер продукта посмотрев на ваши метрики сказал, что ему непонятно что такое RAM/inodes/CPUla. Также он сказал, что хочет понимать, насколько мы выполняем свои обязанности перед клиентами и какое качество обслуживания. Что вы можете ему предложить?
Попытался бы объяснить ему доступным языком 
RAM - количество оперативной памяти, как влияет на производительность высокая нагрузка на чтение/запись в оперативную память
CPU - объяснил бы что такое load average и почему так важно чтобы он не привышал определенных показателей
Inodes - колличество свободных/занятых файловых индексов

Обязанности перед клиентами не работа инженера DevOps но я объяснил бы что:
SLO — целевой уровень качества обслуживания. Целевое значение или диапазон значений
SLA — соглашение об уровне обслуживания. Явный или неявный контракт с внешними пользователями, включающий в себя последствия невыполнения SLO
SLI — индикатор качества обслуживания. Конкретная величина предоставляемого обслуживания
Далее он бы сам выбрал подходящие ему вариант качества обслуживания. 


### 3. Вашей DevOps команде в этом году не выделили финансирование на построение системы сбора логов. Разработчики в свою очередь хотят видеть все ошибки, которые выдают их приложения. Какое решение вы можете предпринять в этой ситуации, чтобы разработчики получали ошибки приложения?

Я бы использовал систему сбора логов Elastic Stack в связке с rsyslog например


### 4. Вы, как опытный SRE, сделали мониторинг, куда вывели отображения выполнения SLA=99% по http кодам ответов. Вычисляете этот параметр по следующей формуле: summ_2xx_requests/summ_all_requests. Данный параметр не поднимается выше 70%, но при этом в вашей системе нет кодов ответа 5xx и 4xx. Где у вас ошибка?

Информационные ответы (100 – 199)
Успешные ответы (200 – 299)
Сообщения о перенаправлении (300 – 399)
Ошибки клиента (400 – 499)
Ошибки сервера (500 – 599)

SLA не может стремиться к 99 так как учитываются и информационные сообщения, которые к ошибкам не относятся.

### 5. Опишите основные плюсы и минусы pull и push систем мониторинга.

Для Pull модели система мониторинга должна иметь возможность “достучаться” до приложения. 
Если оно за NAT использовать Pull становится сложно, ведь нужно как-то прокидывать порт.
У Push достаточно добиться доступности центральной ноды с приложений.

Обнаружение недоступности ноды

У Pull модели ситуация проще: Можно максимально быстро узнать о недоступности, и есть конкретное поведение: рвётся соединение, повышенный таймаут или всплывает ошибка 5ХХ.
У Push модели придётся выяснить конкретную причину: упал агент, весь сервер, неполадки с сетью или приложение вообще стало не доступно.


### 6. Какие из ниже перечисленных систем относятся к push модели, а какие к pull? А может есть гибридные?
        Prometheus - pull модель
        TICK - push модель
        Zabbix - гибридная (push и pull)
        VictoriaMetrics - гибридная (push и pull)
        Nagios - pull модель

### 7. Склонируйте себе репозиторий и запустите TICK-стэк, используя технологии docker и docker-compose.


В виде решения на это упражнение приведите скриншот веб-интерфейса ПО chronograf (http://localhost:8888).

P.S.: если при запуске некоторые контейнеры будут падать с ошибкой - проставьте им режим Z, например ./data:/var/lib:Z
установил
![изображение](https://github.com/IOSorokin/Monitoring/assets/148979909/2ac46b84-4f7b-4f9f-96a8-cf80114e9646)


### 8. Перейдите в веб-интерфейс Chronograf (http://localhost:8888) и откройте вкладку Data explorer.
        Нажмите на кнопку Add a query
        Изучите вывод интерфейса и выберите БД telegraf.autogen
        В measurments выберите cpu->host->telegraf-getting-started, а в fields выберите usage_system. Внизу появится график утилизации cpu.
        Вверху вы можете увидеть запрос, аналогичный SQL-синтаксису. Поэкспериментируйте с запросом, попробуйте изменить группировку и интервал наблюдений.

      Для выполнения задания приведите скриншот с отображением метрик утилизации cpu из веб-интерфейса.

### 9. Изучите список telegraf inputs. Добавьте в конфигурацию telegraf следующий плагин - docker:

[[inputs.docker]]
  endpoint = "unix:///var/run/docker.sock"

## Дополнительно вам может потребоваться донастройка контейнера telegraf в docker-compose.yml дополнительного volume и режима privileged:

  telegraf:
    image: telegraf:1.4.0
    privileged: true
    volumes:
      - ./etc/telegraf.conf:/etc/telegraf/telegraf.conf:Z
      - /var/run/docker.sock:/var/run/docker.sock:Z
    links:
      - influxdb
    ports:
      - "8092:8092/udp"
      - "8094:8094"
      - "8125:8125/udp"

После настройке перезапустите telegraf, обновите веб интерфейс и приведите скриншотом список measurments в веб-интерфейсе базы telegraf.autogen . Там должны появиться метрики, связанные с docker.

Факультативно можете изучить какие метрики собирает telegraf после выполнения данного задания.
Дополнительное задание (со звездочкой*) - необязательно к выполнению

    Вы устроились на работу в стартап. На данный момент у вас нет возможности развернуть полноценную систему мониторинга, и вы решили самостоятельно написать простой python3-скрипт для сбора основных метрик сервера. Вы, как опытный системный-администратор, знаете, что системная информация сервера лежит в директории /proc. Также, вы знаете, что в системе Linux есть планировщик задач cron, который может запускать задачи по расписанию.

Суммировав все, вы спроектировали приложение, которое:

    является python3 скриптом

    собирает метрики из папки /proc

    складывает метрики в файл 'YY-MM-DD-awesome-monitoring.log' в директорию /var/log (YY - год, MM - месяц, DD - день)

    каждый сбор метрик складывается в виде json-строки, в виде:

        timestamp (временная метка, int, unixtimestamp)

        metric_1 (метрика 1)

        metric_2 (метрика 2)

        ...

        metric_N (метрика N)

    сбор метрик происходит каждую 1 минуту по cron-расписанию

Для успешного выполнения задания нужно привести:

а) работающий код python3-скрипта,

б) конфигурацию cron-расписания,

в) пример верно сформированного 'YY-MM-DD-awesome-monitoring.log', имеющий не менее 5 записей,

P.S.: количество собираемых метрик должно быть не менее 4-х. P.P.S.: по желанию можно себя не ограничивать только сбором метрик из /proc.

    В веб-интерфейсе откройте вкладку Dashboards. Попробуйте создать свой dashboard с отображением:
        утилизации ЦПУ
        количества использованного RAM
        утилизации пространства на дисках
        количество поднятых контейнеров
        аптайм
        ...
        фантазируйте)

Как оформить ДЗ?
Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.
